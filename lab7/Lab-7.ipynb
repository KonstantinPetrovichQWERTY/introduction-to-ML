{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab-7: ANN in Pytorch\n",
    "\n",
    "In this lab, you will practice simple deep learning model in one of the most popular frameworks, Pytorch.\n",
    "\n",
    "\n",
    "## Objectives:\n",
    "1. Theoretical issues\n",
    "2. Implementation of basic concepts from scratch \n",
    "3. Get starting in Pytorch\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Theoretical issues\n",
    "Ordinary fully connected neural nets consist of Dense layers, activations, and an output layer.\n",
    "\n",
    "1. What's the difference between deep learning and normal machine learning?\n",
    "<span style=\"color:blue\"> \n",
    "   \n",
    "    1- Adding more data for traditional ML algorithms, won't improve\n",
    "\t  the performance and the learning curve will saturate (plateau), but for DL, you can get better performance.\n",
    "\t<br/>2- There's no feature extraction step in a lot of cases like in CNN\n",
    "\t<br/>3- It needs high computational power in training.\n",
    "2. How does a neural network with no hidden layers and one output neuron compare to a logistic/linear regression?\n",
    "\t* There's no difference. NN with no hidden layers is a perceptron which has the same architecture of logistic/linear regression. If the activation function in the output layer is linear and loss is mse then it is linear regression. If the activation function in the output layer is sigmoid and the loss is the logloss then it is logistic regression.\n",
    "3. How does a neural network with multiple hidden layers but with linear activation and one output neuron compared to logistic/linear regression?\n",
    "\t* Also, there's no difference. Take as an example this image:\n",
    "\t\n",
    "\t![alt text](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-09-at-4-19-50-am.png?w=996&h=736) \n",
    "\t\n",
    "\tDerive the output neuron in this simple network, given the activation function is this linear function: $f(x) = x$, You will find it is a linear combination of the input variables.\n",
    "4. Can the perceptron find a non-linear decision boundary?\n",
    "\t* No, as long as the logits (logOdds which is the input to the sigmoid function) is a linear combination of the input variables then it can only find a linear decision boundary.\n",
    "5. In a multi-hidden layers network, what's the need of a non-linear activation function?\n",
    "\t* To capture the non-linear patterns in the relation between the input and the output.\n",
    "6. Is random weight assignment better than assigning same weights to the units in the hidden layer.\n",
    "\t* Yes, as assigning the same weight to the unit won't learn anything from the error signal propagated from the output layer as the error signal value depends on the value of the weight itels, so the hidden layer before the output layer all of the units will get the same value of the error and they will change to the same value as well and same for all units in the network.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Theory: Feed Forward Neural Network\n",
    "\n",
    "An artificial neural network consists of: \n",
    "\n",
    "- Input Layer  \n",
    "- Hidden Layer(s)\n",
    "- Output Layer\n",
    "\n",
    "The layers consist of units, typically called \"neurons\".  Each neuron (except inputs) connects with the neurons from the previous layer. Each connection has a weight. These weighted inputs are summed together (a linear combination) then passed through an activation function to get the unit's output.\n",
    "\n",
    "Mathematically this equivalent to:\n",
    "<center>\n",
    "\n",
    "$ \n",
    " y = f(w_1x_1 + w_2x_2 + b)\n",
    "$\n",
    " \n",
    "$ \n",
    " y = f\\left(\\sum_{i=1}^{N} w_ix_i + b\\right)\n",
    "$\n",
    "    \n",
    "$\n",
    " y = f(\\vec{x}W + b)\n",
    "$\n",
    "</center>\n",
    "    \n",
    "where:\n",
    "\n",
    "*    $w_{i}$  - weight (just a float number) of connection between i-th neuron from previous layer and the current one; \n",
    "\n",
    "*    b - bias, one for all connections to this neuron; \n",
    "\n",
    "*    $x_i$ - the value of i-th neuron. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1) Tensors - basic data type in Pytorch\n",
    "\n",
    "It turns out neural network computations are just a sequence of linear algebra operations on tensors, a generalization of matrices. A vector is a 1-dimensional tensor, a matrix is a 2-dimensional tensor, an array with three indices is a 3-dimensional tensor (RGB color images for example). The fundamental data structure for neural networks are tensors and PyTorch (as well as pretty much every other deep learning framework) is built around tensors.\n",
    "\n",
    "Just like Numpy arrays, Pytorch tensors can be added, multiplied, subtracted, etc.\n",
    "\n",
    "#### Let's implement a workflow of simple neuron with tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch\n",
    "# !pip3 install torchvision\n",
    "# !pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "def sigmoid_activation(x):\n",
    "    \"\"\" Sigmoid activation function \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        x: torch.Tensor\n",
    "    \"\"\"\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets generate data. We need to compute the output of the neuron. We have 5 input features, just random for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vector for neuron: tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])\n",
      "Weights of input: tensor([[-0.8948, -0.3556,  1.2324,  0.1382, -1.6822]])\n",
      "Bias : tensor([[0.3177]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(7) \n",
    "\n",
    "x = torch.randn((1, 5))\n",
    "weights = torch.randn_like(x)\n",
    "bias = torch.randn((1, 1))\n",
    "\n",
    "print(f\"Input vector for neuron: {x}\")\n",
    "print(f\"Weights of input: {weights}\")\n",
    "print(f\"Bias : {bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**: Calculate the output of the neuron with input features `x`, weights `weights`, and bias `bias`. Similar to Numpy, PyTorch has a [`torch.sum()`](https://pytorch.org/docs/stable/torch.html#torch.sum) function, as well as a `.sum()` method on tensors, for taking sums. Feed this linear sum to the `activation` function to complete the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val: tensor([[-1.6619]])\n",
      "y: tensor([[0.1595]])\n"
     ]
    }
   ],
   "source": [
    "val = torch.sum(weights * x) + bias\n",
    "y = sigmoid_activation(val)\n",
    "print(f'val: {val}')\n",
    "print(f'y: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix multiplication in Pytorch\n",
    "In general, matrix multiplication is more preferable than simple summation and multiplication because of  high-performance computing of this operation on modern GPUs. Thus, your next task: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**:  Do the same operation as in **Task 1** using matrix multiplication\n",
    "\n",
    "You may use [`torch.mm()`](https://pytorch.org/docs/stable/torch.html#torch.mm) or [`torch.matmul()`](https://pytorch.org/docs/stable/torch.html#torch.matmul) for multiplication of tensors. \n",
    "\n",
    "Do not forget to reshape one of them \\(`x` or `weights`, that is your task to choose the proper one\\) to avoid an error. You can apply an operator `.view(a,b)` on a tensor to reshape it into $a,b$ shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of weight matrix: torch.Size([1, 5])\n",
      "Shape of input vector: torch.Size([1, 5])\n",
      "val: tensor([[-1.6619]])\n",
      "y: tensor([[0.1595]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of weight matrix: {weights.shape}\")\n",
    "print(f\"Shape of input vector: {x.shape}\")\n",
    "\n",
    "val = torch.mm(x, weights.view(5, 1)) + bias\n",
    "y = sigmoid_activation(val)\n",
    "\n",
    "print(f'val: {val}')\n",
    "print(f'y: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Multi layer network\n",
    "\n",
    "We saw how to compute the output of a single unit network. The power of neural networks comes when multiple units are stacked into layers. \n",
    "The output of one layer of neurons becomes the input for the next layer. Now the weights should be expressed as a matrix.\n",
    "\n",
    "<img src='./assets/multilayer_diagram_weights.png' width=450px>\n",
    "\n",
    "The bottom layer here are the inputs, surprisingly called the **input layer**. The middle layer is called the **hidden layer**, and the final layer (top) is the **output layer**. We can express this network mathematically with matrices again and use matrix multiplication to get linear combinations for each unit in one operation. For example, the hidden layer ($h_1$ and $h_2$ here) can be calculated: \n",
    "\n",
    "$$\n",
    "\\vec{h} = [h_1 \\, h_2] = \n",
    "\\begin{bmatrix}\n",
    "x_1 \\, x_2 \\cdots \\, x_n\n",
    "\\end{bmatrix}\n",
    "\\cdot \n",
    "\\begin{bmatrix}\n",
    "           w_{11} & w_{12} \\\\\n",
    "           w_{21} &w_{22} \\\\\n",
    "           \\vdots &\\vdots \\\\\n",
    "           w_{n1} &w_{n2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The output for this small network is found by treating the hidden layer as inputs for the output unit. The network output:\n",
    "\n",
    "$$\n",
    "y = f_2(f_1(\\vec{x}\\mathbf{W_2} + B_1)\\mathbf{W_2} + B_2)\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(7) \n",
    "features = torch.randn((1, 3))\n",
    "\n",
    "n_input = features.shape[1]     \n",
    "n_hidden = 2\n",
    "n_output = 1                    \n",
    "\n",
    "W1 = torch.randn(n_input, n_hidden)\n",
    "W2 = torch.randn(n_hidden, n_output)\n",
    "\n",
    "B1 = torch.randn((1, n_hidden))\n",
    "B2 = torch.randn((1, n_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3:** Calculate and print the output for this multi-layer network using the weights `W1` & `W2`, and the biases, `B1` & `B2`. The correct value should be `tensor([[0.3171]])` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3171]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val1 = torch.mm(features, W1) + B1\n",
    "h = sigmoid_activation(val1)\n",
    "\n",
    "val2 = torch.mm(h, W2) + B2\n",
    "y = sigmoid_activation(val2)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Pytorch Autograd\n",
    "\n",
    "Training of neural networks through back propagation requires computation of gradients. Pytorch does it for you automatically: tensors track their computational history and support gradient computation if you set the flag `requires_grad=True` in tensor.\n",
    "\n",
    "The `backward()` function is responsible for calculation of gradients and accumulate (not apply) them in respective tensors\n",
    "\n",
    "The tensor with `requires_grad=True` has attribute to check the gradients values : `grad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5., requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a function of x:  $$f(x) = x^2 + 2x + 1$$\n",
    "\n",
    "The following code will compute and **accumulate** the gradient w.r.t $x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36., grad_fn=<AddBackward0>) True\n",
      "Gradient on tensor before backward(): None\n",
      "Gradient on tensor after backward(): 12.0\n"
     ]
    }
   ],
   "source": [
    "z = x ** 2 + 2*x + 1\n",
    "print(z, z.requires_grad)\n",
    "\n",
    "print(f\"Gradient on tensor before backward(): {x.grad}\")\n",
    "z.backward() \n",
    "print(f\"Gradient on tensor after backward(): {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the previous cell several times and see how the value of the gradient changes. Because the gradient is accumulated everytime you call `backward()` it is important to zero the accumulated values before any calculations, i.e., `x.grad = None` or `zero_grad()` for optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x.grad = None\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent PyTorch from tracking the history and forming the backward graph, the code can be wrapped inside with torch.no_grad(): it will make the code run faster whenever gradient tracking is not needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.requires_grad True\n",
      "Value of z: 36.0, Requires grad?: False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.tensor(5.0, requires_grad=True)\n",
    "    print(f\"x.requires_grad {x.requires_grad}\")\n",
    "    \n",
    "    z_no_grad = x ** 2 + 2*x + 1\n",
    "    \n",
    "    print(f\"Value of z: {z_no_grad}, Requires grad?: {z_no_grad.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) Tensor to numpy array and vice-versa\n",
    "\n",
    "PyTorch has a great feature for converting between Numpy arrays and Torch tensors. To create a tensor from a Numpy array, use `torch.from_numpy()`. To convert a tensor to a Numpy array, use the `.numpy()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11210881, 0.3419253 , 0.49908237],\n",
       "       [0.19899259, 0.4787396 , 0.92937914],\n",
       "       [0.87147951, 0.47027695, 0.24705509],\n",
       "       [0.79439809, 0.15705859, 0.66329577]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.rand(4,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1121, 0.3419, 0.4991],\n",
       "        [0.1990, 0.4787, 0.9294],\n",
       "        [0.8715, 0.4703, 0.2471],\n",
       "        [0.7944, 0.1571, 0.6633]], dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11210881, 0.3419253 , 0.49908237],\n",
       "       [0.19899259, 0.4787396 , 0.92937914],\n",
       "       [0.87147951, 0.47027695, 0.24705509],\n",
       "       [0.79439809, 0.15705859, 0.66329577]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## 2) Model Design in Pytorch\n",
    "Now we're going to build a larger network that can solve a (formerly) difficult problem -  identifying text on an image. We'll use the **MNIST dataset** consisting of grayscale handwritten digits. Each image has 28x28 pixels, you can see the samples below:\n",
    " \n",
    "<img src=\"./assets/mnist.png\" width=\"500px\"> \n",
    "\n",
    "Our goal is to build a neural network that takes one of these images and predicts the corresponding digit. \n",
    "\n",
    "We have three parts that we need to build:\n",
    "1. **Data Loading process** - how to handle data in Pytorch.\n",
    "2. **Model building** - how to create a neural network with desirable parameters.\n",
    "3. **Training loop** - how to properly train the model and evaluate its performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Data Loading\n",
    "\n",
    "1. **Data Transformations** - similar to data preprocessing techniques that we used before, but more image-oriented. You can specify a sequence of transformations, such as normalization, cropping (getting the region of image), resizing, etc. \n",
    "2. **Data Source** - load of built-in (or custom) data sets. For a data set you can specify the transformations from the previous step, and Pytorch will transform each sample automatically.\n",
    "3. **Data Loader** - Pytorch class that makes working with the data sets easy and fast. For example, it can iterate over the batches of data during the training for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:13<00:00, 742kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 197kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.03MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.73MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "test_batch_size = 100\n",
    "\n",
    "data_transformations = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           # Normalize an image with mean 0.1307 and standard deviation 0.3081.\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])\n",
    "\n",
    "mnist_train = datasets.MNIST('./data', train=True, download=True,\n",
    "                           transform=data_transformations)\n",
    "mnist_test = datasets.MNIST('./data', train=False,\n",
    "                            transform=data_transformations)\n",
    "\n",
    "train_loader = DataLoader(mnist_train,\n",
    "                          batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test,\n",
    "                         batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18749f82570>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(f\"Label={labels[0]}\")\n",
    "plt.imshow(images[0].reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2) Model building\n",
    "\n",
    "Pytorch provides a module `nn` that makes building networks relatively simple. To create your own network you need to:\n",
    "\n",
    "1. Create a class and inherit it from `nn.Module`. This is the main parent class for all Pytorch models.\n",
    "2. Implement a constructor, i.e. a function `def __init__(self): ...`, where you should describe the architecture of a network and its parameters.\n",
    "3. Define a function `def forward(self, x): ...`, which gets the input batch `x` as an argument, creates  the flow of data through the defined layers and returns the answer.\n",
    "\n",
    "#### Example of the *same network* that we've already implemented from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToyNet model architecture:\n",
      " ToyNet(\n",
      "  (hidden): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (output): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "Prediction of tensor([[-1.0587,  0.3344, -0.7804]]) : tensor([[0.4100]], grad_fn=<SigmoidBackward0>)\n",
      "Prediction of tensor([[-1.0587,  0.3344, -0.7804]]) by .forward : tensor([[0.4100]], grad_fn=<SigmoidBackward0>)\n",
      "Prediction on batch: tensor([[0.4309],\n",
      "        [0.4010],\n",
      "        [0.4142],\n",
      "        [0.3929]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import sigmoid\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "class ToyNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ToyNet, self).__init__()\n",
    "        self.hidden = nn.Linear(3, 2)        \n",
    "        self.output = nn.Linear(2, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = sigmoid(self.hidden(x))\n",
    "        x = self.output(x)\n",
    "        return sigmoid(x)\n",
    "\n",
    "\n",
    "model = ToyNet().to(device)\n",
    "\n",
    "print(f\"ToyNet model architecture:\\n {model}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "toy_x = torch.randn((1,3))\n",
    "print(f\"Prediction of {toy_x} : {model(toy_x)}\")\n",
    "print(f\"Prediction of {toy_x} by .forward : {model.forward(toy_x)}\")\n",
    "toy_xs = torch.randn((4,3))\n",
    "print(f\"Prediction on batch: {model(toy_xs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**. This network is not trained yet and does some meaningless calculations. Here we just got acquainted with the representation on NN in PyTorch. Training process will be discussed in the further snippets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation functions\n",
    "The choice of activation function is important for architecture construction, because it leads to different non-linearity of a layer. For now we worked with sigmoid only, but usually (not necessary) it is applied on the output layer only. **ReLU** (Rectified Linear Unit) is a quite popular activation function for hidden layers: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4:** Complete the implementation of the following network to solve the classification task on MNIST\n",
    "\n",
    "<img src='./assets/Model.png' width=700px>\n",
    "\n",
    "So, you should specify 2 hidden layers with 256 and 100 neurons respectively, and an output layer with 10 neurons (probability of the classes). Your network will get an image, or 28x28 matrix, and flatten it to 1D array. You also should write the flow of this input array through the network, resulting in a 1x10 array (for one image). Hidden layers should be activited by *ReLU*, output - by *Logarithmyc SoftMax*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (hidden2): Linear(in_features=256, out_features=100, bias=True)\n",
      "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden1 = nn.Linear(28 * 28, 256)\n",
    "        self.hidden2 = nn.Linear(256, 100)\n",
    "        self.output = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        return F.log_softmax(self.output(x), dim=1)\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.3) Training loop\n",
    "We should define the loops over the batches and run the training on. Lets specify the hyperparameters of the model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "criterion = nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    bar = tqdm(train_loader)\n",
    "    iteration = 0\n",
    "    overall_loss = 0\n",
    "    \n",
    "    for data, target in bar:\n",
    "    \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iteration += 1\n",
    "        overall_loss += loss.item()\n",
    "        bar.set_postfix({\"Loss\": format(overall_loss/iteration, '.6f')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  \n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f\"Test set: Average loss: {test_loss}, Accuracy: {100. * correct / len(test_loader.dataset)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:38<00:00, 49.20it/s, Loss=0.402661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 2.0593969802856447e-05, Accuracy: 93.9 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:32<00:00, 58.37it/s, Loss=0.165186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.4231490149497985e-05, Accuracy: 95.64 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:29<00:00, 63.30it/s, Loss=0.113554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.0285690717697143e-05, Accuracy: 96.77 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:29<00:00, 64.64it/s, Loss=0.085017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 9.639221767187119e-06, Accuracy: 97.02 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:30<00:00, 62.27it/s, Loss=0.066739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 7.443744359612466e-06, Accuracy: 97.68 \n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "\n",
    "#torch.save(model.state_dict(), \"mnist_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to check if the neural network model is overfitting?\n",
    "\n",
    "Track the training and the testing losses during the training, if the loss on test set starts increasing then the model is overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
